{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a5895a-9aeb-41e9-8a76-e3ecaf1ffcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "import os                        \n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0cb28b-ae05-49be-b7cd-8e63cd8e41f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3820 images belonging to 2 classes.\n",
      "Found 474 images belonging to 2 classes.\n",
      "Found 488 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "   rescale=1./255,\n",
    "   shear_range = 0.15,\n",
    "   zoom_range = 0.15,\n",
    "   horizontal_flip = True\n",
    ")\n",
    "\n",
    "img_height=256\n",
    "img_width=256\n",
    "bs=32\n",
    "\n",
    "train_ds = datagen.flow_from_directory(\n",
    "    'split_dataset/train',\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = bs,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)\n",
    "\n",
    "val_ds = datagen.flow_from_directory(\n",
    "    'split_dataset/val',\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = bs,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_ds = datagen.flow_from_directory(\n",
    "    'split_dataset/test',\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = bs,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a53e64c6-7f80-4ad3-9b84-802f4970b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Input\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Input(shape=input_shape))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units = 512, activation = 'relu'))\n",
    "classifier.add(BatchNormalization()),\n",
    "classifier.add(Dense(256,activation='relu')),\n",
    "classifier.add(Dropout(0.25)),\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce86b564-5ff6-4679-ad23-09c5996d8f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123008</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">62,980,608</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123008\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │      \u001b[38;5;34m62,980,608\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,124,385</span> (240.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,124,385\u001b[0m (240.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,123,361</span> (240.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,123,361\u001b[0m (240.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb0b9ff-8f0f-49e2-bda5-836ca96ff228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 2s/step - accuracy: 0.6433 - loss: 0.6846 - val_accuracy: 0.7890 - val_loss: 0.4970\n",
      "Epoch 2/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.7500 - loss: 0.2380 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python312\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.7761 - loss: 0.4830 - val_accuracy: 0.7595 - val_loss: 0.5641\n",
      "Epoch 4/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165us/step - accuracy: 0.7188 - loss: 0.3023 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.7901 - loss: 0.4415 - val_accuracy: 0.7658 - val_loss: 0.5081\n",
      "Epoch 6/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180us/step - accuracy: 0.9062 - loss: 0.1444 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.8183 - loss: 0.4172 - val_accuracy: 0.6456 - val_loss: 0.7761\n",
      "Epoch 8/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255us/step - accuracy: 0.8438 - loss: 0.1985 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.8175 - loss: 0.3952 - val_accuracy: 0.5464 - val_loss: 1.0435\n",
      "Epoch 10/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386us/step - accuracy: 0.7500 - loss: 0.2320 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.8254 - loss: 0.3953 - val_accuracy: 0.8228 - val_loss: 0.4203\n",
      "Epoch 12/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248us/step - accuracy: 0.7812 - loss: 0.2411 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 13/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.8347 - loss: 0.3620 - val_accuracy: 0.7700 - val_loss: 0.4664\n",
      "Epoch 14/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310us/step - accuracy: 0.7812 - loss: 0.2932 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 15/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.8372 - loss: 0.3651 - val_accuracy: 0.8122 - val_loss: 0.5096\n",
      "Epoch 16/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242us/step - accuracy: 0.7500 - loss: 0.2449 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 17/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.8556 - loss: 0.3299 - val_accuracy: 0.8101 - val_loss: 0.4027\n",
      "Epoch 18/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183us/step - accuracy: 0.9375 - loss: 0.1510 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 19/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.8488 - loss: 0.3401 - val_accuracy: 0.6730 - val_loss: 1.0775\n",
      "Epoch 20/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449us/step - accuracy: 0.7812 - loss: 0.1644 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 21/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.8503 - loss: 0.3202 - val_accuracy: 0.8249 - val_loss: 0.3922\n",
      "Epoch 22/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step - accuracy: 0.7188 - loss: 0.2620 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 23/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.8563 - loss: 0.3051 - val_accuracy: 0.6730 - val_loss: 0.6259\n",
      "Epoch 24/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254us/step - accuracy: 0.8750 - loss: 0.1308 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 25/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.8518 - loss: 0.3174 - val_accuracy: 0.8333 - val_loss: 0.3999\n",
      "Epoch 26/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259us/step - accuracy: 0.8438 - loss: 0.1348 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 27/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.8692 - loss: 0.3097 - val_accuracy: 0.8397 - val_loss: 0.4001\n",
      "Epoch 28/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189us/step - accuracy: 0.8750 - loss: 0.1451 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 29/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1228s\u001b[0m 10s/step - accuracy: 0.8740 - loss: 0.2754 - val_accuracy: 0.8249 - val_loss: 0.4151\n",
      "Epoch 30/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.8438 - loss: 0.2070 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 31/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.8691 - loss: 0.3042 - val_accuracy: 0.7806 - val_loss: 0.4365\n",
      "Epoch 32/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - accuracy: 0.8125 - loss: 0.2453 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 33/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.8779 - loss: 0.2776 - val_accuracy: 0.8586 - val_loss: 0.3228\n",
      "Epoch 34/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263us/step - accuracy: 0.9375 - loss: 0.1038 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 35/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.8782 - loss: 0.2722 - val_accuracy: 0.8228 - val_loss: 0.4224\n",
      "Epoch 36/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226us/step - accuracy: 0.8438 - loss: 0.1367 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 37/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1028s\u001b[0m 9s/step - accuracy: 0.8830 - loss: 0.2567 - val_accuracy: 0.8291 - val_loss: 0.3795\n",
      "Epoch 38/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.0722 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 39/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.8839 - loss: 0.2531 - val_accuracy: 0.8544 - val_loss: 0.3592\n",
      "Epoch 40/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.8438 - loss: 0.1744 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 41/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 1s/step - accuracy: 0.8863 - loss: 0.2563 - val_accuracy: 0.8333 - val_loss: 0.4114\n",
      "Epoch 42/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301us/step - accuracy: 0.8125 - loss: 0.1655 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 43/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 1s/step - accuracy: 0.8825 - loss: 0.2642 - val_accuracy: 0.7911 - val_loss: 0.5813\n",
      "Epoch 44/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147us/step - accuracy: 0.8750 - loss: 0.1412 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 45/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 1s/step - accuracy: 0.8861 - loss: 0.2545 - val_accuracy: 0.8354 - val_loss: 0.4620\n",
      "Epoch 46/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.8125 - loss: 0.2196 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 47/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 1s/step - accuracy: 0.8875 - loss: 0.2577 - val_accuracy: 0.8439 - val_loss: 0.3989\n",
      "Epoch 48/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.9688 - loss: 0.1203 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 49/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 5s/step - accuracy: 0.9004 - loss: 0.2411 - val_accuracy: 0.8312 - val_loss: 0.4503\n",
      "Epoch 50/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - accuracy: 0.8438 - loss: 0.1045 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 51/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 2s/step - accuracy: 0.9014 - loss: 0.2266 - val_accuracy: 0.8692 - val_loss: 0.3325\n",
      "Epoch 52/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.0654 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 53/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9026 - loss: 0.2282 - val_accuracy: 0.8650 - val_loss: 0.3592\n",
      "Epoch 54/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 0.8438 - loss: 0.1430 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 55/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.9015 - loss: 0.2176 - val_accuracy: 0.8755 - val_loss: 0.3451\n",
      "Epoch 56/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.8438 - loss: 0.1592 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 57/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 1s/step - accuracy: 0.9085 - loss: 0.2182 - val_accuracy: 0.8650 - val_loss: 0.3467\n",
      "Epoch 58/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - accuracy: 0.8750 - loss: 0.1484 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 59/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9034 - loss: 0.2241 - val_accuracy: 0.8629 - val_loss: 0.3147\n",
      "Epoch 60/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432us/step - accuracy: 0.9375 - loss: 0.0827 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 61/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 1s/step - accuracy: 0.9120 - loss: 0.1999 - val_accuracy: 0.7975 - val_loss: 0.4811\n",
      "Epoch 62/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - accuracy: 0.8750 - loss: 0.1121 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 63/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 1s/step - accuracy: 0.9044 - loss: 0.2303 - val_accuracy: 0.8523 - val_loss: 0.3596\n",
      "Epoch 64/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.8750 - loss: 0.0876 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 65/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 1s/step - accuracy: 0.9130 - loss: 0.2016 - val_accuracy: 0.8312 - val_loss: 0.4068\n",
      "Epoch 66/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.9688 - loss: 0.0511 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 67/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 1s/step - accuracy: 0.9104 - loss: 0.2023 - val_accuracy: 0.8671 - val_loss: 0.3923\n",
      "Epoch 68/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step - accuracy: 0.8750 - loss: 0.1616 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 69/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.9087 - loss: 0.2187 - val_accuracy: 0.8797 - val_loss: 0.3458\n",
      "Epoch 70/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448us/step - accuracy: 0.8125 - loss: 0.1316 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 71/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 1s/step - accuracy: 0.9154 - loss: 0.1918 - val_accuracy: 0.8565 - val_loss: 0.4095\n",
      "Epoch 72/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233us/step - accuracy: 0.9375 - loss: 0.0527 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 73/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1294s\u001b[0m 11s/step - accuracy: 0.9109 - loss: 0.1987 - val_accuracy: 0.8586 - val_loss: 0.3713\n",
      "Epoch 74/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.9688 - loss: 0.0402 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 75/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6340s\u001b[0m 54s/step - accuracy: 0.9121 - loss: 0.1919 - val_accuracy: 0.8797 - val_loss: 0.3506\n",
      "Epoch 76/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8750 - loss: 0.1551 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 77/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2s/step - accuracy: 0.9205 - loss: 0.1858 - val_accuracy: 0.8840 - val_loss: 0.2901\n",
      "Epoch 78/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.9375 - loss: 0.0576 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 79/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step - accuracy: 0.9052 - loss: 0.2219 - val_accuracy: 0.8544 - val_loss: 0.3374\n",
      "Epoch 80/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.9375 - loss: 0.0829 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 81/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step - accuracy: 0.9138 - loss: 0.1950 - val_accuracy: 0.8840 - val_loss: 0.2987\n",
      "Epoch 82/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.9375 - loss: 0.0863 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 83/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13041s\u001b[0m 110s/step - accuracy: 0.9186 - loss: 0.1795 - val_accuracy: 0.8586 - val_loss: 0.3717\n",
      "Epoch 84/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455us/step - accuracy: 0.8125 - loss: 0.1247 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 85/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9307 - loss: 0.1740 - val_accuracy: 0.8333 - val_loss: 0.6348\n",
      "Epoch 86/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399us/step - accuracy: 0.8750 - loss: 0.1647 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 87/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.9260 - loss: 0.1695 - val_accuracy: 0.8481 - val_loss: 0.3686\n",
      "Epoch 88/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466us/step - accuracy: 0.9688 - loss: 0.1104 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 89/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9153 - loss: 0.1714 - val_accuracy: 0.8650 - val_loss: 0.4834\n",
      "Epoch 90/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313us/step - accuracy: 0.8750 - loss: 0.1100 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 91/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9208 - loss: 0.1803 - val_accuracy: 0.8650 - val_loss: 0.3999\n",
      "Epoch 92/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326us/step - accuracy: 0.9688 - loss: 0.0523 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 93/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9270 - loss: 0.1688 - val_accuracy: 0.8819 - val_loss: 0.2807\n",
      "Epoch 94/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.8750 - loss: 0.1232 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 95/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9308 - loss: 0.1725 - val_accuracy: 0.8882 - val_loss: 0.3222\n",
      "Epoch 96/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218us/step - accuracy: 0.9375 - loss: 0.0966 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 97/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9255 - loss: 0.1646 - val_accuracy: 0.8713 - val_loss: 0.3894\n",
      "Epoch 98/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - accuracy: 0.9375 - loss: 0.0668 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 99/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9317 - loss: 0.1574 - val_accuracy: 0.8776 - val_loss: 0.3245\n",
      "Epoch 100/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344us/step - accuracy: 0.9688 - loss: 0.0768 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 101/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9331 - loss: 0.1580 - val_accuracy: 0.8755 - val_loss: 0.3288\n",
      "Epoch 102/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440us/step - accuracy: 0.9688 - loss: 0.0581 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 103/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.9453 - loss: 0.1324 - val_accuracy: 0.8987 - val_loss: 0.3456\n",
      "Epoch 104/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.9688 - loss: 0.0853 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 105/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.9360 - loss: 0.1511 - val_accuracy: 0.8797 - val_loss: 0.3582\n",
      "Epoch 106/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - accuracy: 0.9375 - loss: 0.0551 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 107/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9397 - loss: 0.1325 - val_accuracy: 0.8840 - val_loss: 0.3783\n",
      "Epoch 108/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200us/step - accuracy: 0.9062 - loss: 0.1281 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 109/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9327 - loss: 0.1471 - val_accuracy: 0.8797 - val_loss: 0.4264\n",
      "Epoch 110/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286us/step - accuracy: 0.9062 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 111/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9405 - loss: 0.1468 - val_accuracy: 0.8608 - val_loss: 0.4681\n",
      "Epoch 112/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - accuracy: 0.9688 - loss: 0.0332 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 113/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9324 - loss: 0.1573 - val_accuracy: 0.8165 - val_loss: 0.5052\n",
      "Epoch 114/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237us/step - accuracy: 0.9375 - loss: 0.0527 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 115/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9296 - loss: 0.1707 - val_accuracy: 0.8861 - val_loss: 0.3335\n",
      "Epoch 116/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319us/step - accuracy: 0.9375 - loss: 0.0495 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 117/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9318 - loss: 0.1525 - val_accuracy: 0.8797 - val_loss: 0.3543\n",
      "Epoch 118/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 1.0000 - loss: 0.0266 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 119/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9437 - loss: 0.1386 - val_accuracy: 0.8734 - val_loss: 0.4286\n",
      "Epoch 120/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475us/step - accuracy: 0.8438 - loss: 0.1674 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 121/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9434 - loss: 0.1329 - val_accuracy: 0.8819 - val_loss: 0.4270\n",
      "Epoch 122/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256us/step - accuracy: 0.9688 - loss: 0.0472 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 123/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9441 - loss: 0.1416 - val_accuracy: 0.8713 - val_loss: 0.3732\n",
      "Epoch 124/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.9688 - loss: 0.0428 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 125/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9529 - loss: 0.1231 - val_accuracy: 0.8460 - val_loss: 0.4019\n",
      "Epoch 126/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - accuracy: 0.9688 - loss: 0.0343 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 127/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9416 - loss: 0.1394 - val_accuracy: 0.8629 - val_loss: 0.5280\n",
      "Epoch 128/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step - accuracy: 0.9375 - loss: 0.0643 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 129/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.9363 - loss: 0.1358 - val_accuracy: 0.8755 - val_loss: 0.4246\n",
      "Epoch 130/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316us/step - accuracy: 0.9375 - loss: 0.0697 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 131/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9456 - loss: 0.1264 - val_accuracy: 0.8903 - val_loss: 0.3152\n",
      "Epoch 132/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379us/step - accuracy: 0.9688 - loss: 0.0480 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 133/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9440 - loss: 0.1204 - val_accuracy: 0.8692 - val_loss: 0.4643\n",
      "Epoch 134/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350us/step - accuracy: 0.8750 - loss: 0.1523 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 135/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9432 - loss: 0.1301 - val_accuracy: 0.8840 - val_loss: 0.3601\n",
      "Epoch 136/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388us/step - accuracy: 0.9167 - loss: 0.1022 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 137/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9470 - loss: 0.1362 - val_accuracy: 0.9008 - val_loss: 0.2780\n",
      "Epoch 138/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.9688 - loss: 0.0569 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 139/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9573 - loss: 0.1059 - val_accuracy: 0.8924 - val_loss: 0.4209\n",
      "Epoch 140/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - accuracy: 0.9375 - loss: 0.0873 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 141/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9421 - loss: 0.1363 - val_accuracy: 0.8840 - val_loss: 0.3532\n",
      "Epoch 142/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202us/step - accuracy: 0.9688 - loss: 0.0433 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 143/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.9452 - loss: 0.1255 - val_accuracy: 0.8692 - val_loss: 0.6337\n",
      "Epoch 144/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262us/step - accuracy: 0.9688 - loss: 0.0566 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 145/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9475 - loss: 0.1259 - val_accuracy: 0.8734 - val_loss: 0.4005\n",
      "Epoch 146/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step - accuracy: 0.9375 - loss: 0.0496 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 147/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9512 - loss: 0.1232 - val_accuracy: 0.7743 - val_loss: 0.6172\n",
      "Epoch 148/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401us/step - accuracy: 0.9375 - loss: 0.0520 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 149/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.9383 - loss: 0.1477 - val_accuracy: 0.8966 - val_loss: 0.3237\n",
      "Epoch 150/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296us/step - accuracy: 1.0000 - loss: 0.0251 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 151/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.9489 - loss: 0.1180 - val_accuracy: 0.8966 - val_loss: 0.3719\n",
      "Epoch 152/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203us/step - accuracy: 0.9062 - loss: 0.1309 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 153/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.9572 - loss: 0.1047 - val_accuracy: 0.8608 - val_loss: 0.4316\n",
      "Epoch 154/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302us/step - accuracy: 0.9375 - loss: 0.0738 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 155/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9473 - loss: 0.1432 - val_accuracy: 0.8882 - val_loss: 0.3173\n",
      "Epoch 156/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 157/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9512 - loss: 0.1193 - val_accuracy: 0.8882 - val_loss: 0.4015\n",
      "Epoch 158/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319us/step - accuracy: 0.9688 - loss: 0.0702 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 159/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9533 - loss: 0.1089 - val_accuracy: 0.8966 - val_loss: 0.3171\n",
      "Epoch 160/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217us/step - accuracy: 0.9688 - loss: 0.0268 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 161/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9433 - loss: 0.1255 - val_accuracy: 0.8861 - val_loss: 0.3553\n",
      "Epoch 162/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.8750 - loss: 0.1345 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 163/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.9506 - loss: 0.1165 - val_accuracy: 0.8734 - val_loss: 0.4269\n",
      "Epoch 164/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 281us/step - accuracy: 1.0000 - loss: 0.0268 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 165/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - accuracy: 0.9548 - loss: 0.1128 - val_accuracy: 0.8966 - val_loss: 0.3958\n",
      "Epoch 166/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 167/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9554 - loss: 0.1073 - val_accuracy: 0.8755 - val_loss: 0.3760\n",
      "Epoch 168/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251us/step - accuracy: 0.9688 - loss: 0.0595 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 169/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9472 - loss: 0.1402 - val_accuracy: 0.8882 - val_loss: 0.4059\n",
      "Epoch 170/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - accuracy: 0.9688 - loss: 0.0826 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 171/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9524 - loss: 0.1159 - val_accuracy: 0.8819 - val_loss: 0.3898\n",
      "Epoch 172/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328us/step - accuracy: 0.9688 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 173/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 1s/step - accuracy: 0.9585 - loss: 0.1046 - val_accuracy: 0.8903 - val_loss: 0.3809\n",
      "Epoch 174/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 215us/step - accuracy: 0.9688 - loss: 0.0454 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 175/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9498 - loss: 0.1087 - val_accuracy: 0.8797 - val_loss: 0.4669\n",
      "Epoch 176/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295us/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 177/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9575 - loss: 0.1092 - val_accuracy: 0.8165 - val_loss: 0.8105\n",
      "Epoch 178/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318us/step - accuracy: 0.9167 - loss: 0.0934 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 179/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 2s/step - accuracy: 0.9563 - loss: 0.1122 - val_accuracy: 0.8713 - val_loss: 0.4246\n",
      "Epoch 180/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305us/step - accuracy: 0.9688 - loss: 0.0663 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 181/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9571 - loss: 0.1033 - val_accuracy: 0.8861 - val_loss: 0.4628\n",
      "Epoch 182/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - accuracy: 0.9375 - loss: 0.0623 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 183/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9545 - loss: 0.1053 - val_accuracy: 0.8924 - val_loss: 0.3886\n",
      "Epoch 184/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375us/step - accuracy: 0.9375 - loss: 0.0587 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 185/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9628 - loss: 0.0864 - val_accuracy: 0.8797 - val_loss: 0.5451\n",
      "Epoch 186/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431us/step - accuracy: 0.9688 - loss: 0.0678 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 187/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.9531 - loss: 0.1150 - val_accuracy: 0.8734 - val_loss: 0.4820\n",
      "Epoch 188/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303us/step - accuracy: 0.9688 - loss: 0.0493 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 189/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9628 - loss: 0.0942 - val_accuracy: 0.9008 - val_loss: 0.4095\n",
      "Epoch 190/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227us/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 191/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 1s/step - accuracy: 0.9680 - loss: 0.0851 - val_accuracy: 0.8650 - val_loss: 0.4826\n",
      "Epoch 192/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236us/step - accuracy: 0.9688 - loss: 0.0559 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 193/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9502 - loss: 0.1198 - val_accuracy: 0.8945 - val_loss: 0.3736\n",
      "Epoch 194/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431us/step - accuracy: 0.9375 - loss: 0.0507 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 195/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9612 - loss: 0.0892 - val_accuracy: 0.8861 - val_loss: 0.4631\n",
      "Epoch 196/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - accuracy: 0.9375 - loss: 0.0346 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 197/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9554 - loss: 0.0956 - val_accuracy: 0.8945 - val_loss: 0.4137\n",
      "Epoch 198/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260us/step - accuracy: 0.9688 - loss: 0.0351 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 199/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9612 - loss: 0.0929 - val_accuracy: 0.8903 - val_loss: 0.4357\n",
      "Epoch 200/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 201/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9682 - loss: 0.0865 - val_accuracy: 0.8776 - val_loss: 0.4372\n",
      "Epoch 202/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162us/step - accuracy: 0.9688 - loss: 0.0485 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 203/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9660 - loss: 0.0891 - val_accuracy: 0.8882 - val_loss: 0.4959\n",
      "Epoch 204/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161us/step - accuracy: 0.9062 - loss: 0.1043 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 205/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9630 - loss: 0.0862 - val_accuracy: 0.8903 - val_loss: 0.4310\n",
      "Epoch 206/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208us/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 207/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9609 - loss: 0.1051 - val_accuracy: 0.8903 - val_loss: 0.4004\n",
      "Epoch 208/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212us/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 209/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9599 - loss: 0.0895 - val_accuracy: 0.9177 - val_loss: 0.4154\n",
      "Epoch 210/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235us/step - accuracy: 0.8750 - loss: 0.0748 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 211/211\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - accuracy: 0.9632 - loss: 0.0860 - val_accuracy: 0.8861 - val_loss: 0.4712\n"
     ]
    }
   ],
   "source": [
    "total_train_samples = 1910 + 1910  \n",
    "total_val_samples = 237 + 237\n",
    "\n",
    "spe = int(round(total_train_samples/32))      #32 is batch size\n",
    "vs = int(round(total_val_samples/32))\n",
    "\n",
    "model_info = classifier.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch = spe,\n",
    "    epochs = 211,\n",
    "    validation_data = val_ds,\n",
    "    validation_steps = vs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a22bca8f-73d2-4b7f-8cdd-08270d6509dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 500ms/step - accuracy: 0.8982 - loss: 0.3028\n",
      "Loss: 0.3834225535392761 Accuracy: 0.9036885499954224\n"
     ]
    }
   ],
   "source": [
    "score=classifier.evaluate(test_ds)\n",
    "print(\"Loss:\",score[0],\"Accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eeea428-669e-4ad7-8da6-2a5c32dd8a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "classifier.save('glaucoma_detection1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5f180-a25b-47ee-b58a-5ee904f73770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
